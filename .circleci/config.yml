version: 2.1

parameters:
    # Parameters required to trigger the execution of the "host_docs" job
    GITHUB_RUN_URL:
        type: string
        default: none

workflows:
  version: 2
  wait:
    jobs:
      - wait-action
  build-doc-and-deploy-documentation:
    # action trigger by updating the link of github
    when:
      not:
        equal: [none, << pipeline.parameters.GITHUB_RUN_URL >>]
    jobs:
      - build-documentation
      - get-tests-reports
      - deploy-documentation:
          requires:
            - get-tests-reports
            - build-documentation

jobs:
  build-documentation:
    docker:
      - image: cimg/python:3.13.2
    environment:
      - PYTHON_VERSION: "3.13"
      - OPENBLAS_NUM_THREADS: "1"
    steps:
      - checkout
      - run: 
          name:
            'Checkout to PR commit'
          command: 
            bash ./tools/documentation/circleci/checkout_merge_commit.sh
      - restore_cache:
          key: saved-cache
      - run:
          name: "Create the environment for building the documentation"
          command: 
            bash ./tools/documentation/circleci/setup_virtual_environment.sh
      - run:
          name: "Build documentation"
          command: 
            bash ./tools/documentation/circleci/build_doc.sh
          no_output_timeout: 40m
      - run:
          name: "check links"
          command: |
            source .venv/bin/activate
            make -C docs linkcheck 
      # store the documentation for see it in a PR
      - store_artifacts:
          path: docs/_build/html
          destination: documentation
      - store_artifacts:
          path: ~/output_sphinx.log
          destination: log.txt
      # Persists generated documentation so that it can be attached and deployed
      # in the 'deploy-documentation' step.
      - persist_to_workspace:
          root: docs/_build/html
          paths: .
      - save_cache:
          # cache some library
          key: saved-cache
          paths:
            - /home/circleci/nilearn_data
            - /home/circleci/sklearn_data

  get-tests-reports:
    docker:
      - image: cimg/base:2025.05
    environment:
      - GITHUB_ARTIFACT_URL: << pipeline.parameters.GITHUB_RUN_URL >>
    steps:
      - checkout
      - run:
            name: "get reports"
            command: |
              set -x -e
              wget $GITHUB_ARTIFACT_URL
              unzip pytest-results-all.zip -d test_reports
              mkdir -p docs/_build/html
              mv test_reports docs/_build/html
      # store the reports to display for a PR
      - store_artifacts:
          path: docs/_build/html/test_reports
          destination: documentation/test_reports
      # store the reports for adding them to the documentation
      - persist_to_workspace:
          root: docs/_build/html/
          paths: .

  deploy-documentation:
    docker:
      - image: cimg/deploy:2025.01
    environment:
      - USERNAME: "hidimstat-circleci"
      - ORGANIZATION: "hidimstat"
      - DOC_REPO: "hidimstat.github.io"
      - DOC_URL: ""
      - EMAIL: "hidimstat@circleci.com"
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
            - "SHA256:8Ryl+7R+ElSw3nmGIeoEwKJth2nxOO3G/a3cHQscAfA"
      # Attach documentation generated in the 'build-documentation' step so that it can be
      # deployed.
      - attach_workspace:
          at: docs/_build/html
      - run:
          name: 
            "Add the ssh key and list the file in the documentation"
          command: |
              mkdir -p ~/.ssh
              ssh-keyscan github.com >> ~/.ssh/known_hosts
              ls -ltrh docs/_build/html
      - run:
          name: "Deploy documentation"
          command: |
            if [[ "${CIRCLE_BRANCH}" =~ ^main$|^[0-9]+\.[0-9]+\.X$ ]]; then
              bash ./tools/documentation/circleci/push_doc.sh docs/_build/html
            fi

  # this action is only to avoid any error
  wait-action:
    docker:
      - image: cimg/base:2025.05
    steps:
      - run:
            name: "wait"
            command: sleep 10

