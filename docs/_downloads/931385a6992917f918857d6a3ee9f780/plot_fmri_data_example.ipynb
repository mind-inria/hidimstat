{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Support recovery on fMRI data\n\nThis example compares several methods that estimate a decoder map support\nwith statistical guarantees. More precisely, we aim at thresholding the\nweights of some estimated decoder maps according to the confidence we have\nthat they are nonzero. Here, we work with the Haxby dataset and we focus on\nthe 'face vs house' contrast. Thus, we consider the labeled activation maps\nof a given subject and try produce a brain map that corresponds to the\ndiscriminative pattern that makes the decoding of the two conditions.\n\nIn this example, we show that standard statistical methods (i.e., method\nsuch as thresholding by permutation test the SVR or Ridge decoder or the\nalgorithm introduced by Gaonkar et al. [1]_) are not powerful when applied on\nthe uncompressed problem (i.e., the orignal problem in which the activation\nmaps are not reduced using compression techniques such as parcellation).\nThis is notably due to the high dimensionality (too many voxels) and\nstructure of the data (too much correlation between neighboring voxels).\nWe also present two methods that offer statistical guarantees but\nwith a (small) spatial tolerance on the shape of the support:\nclustered desparsified lasso (CLuDL) combines clustering (parcellation)\nand statistical inference ; ensemble of clustered desparsified lasso (EnCluDL)\nadds a randomization step over the choice of clustering.\n\nEnCluDL is powerful and does not depend on a unique clustering choice.\nAs shown in Chevalier et al. (2021) [2]_, for several tasks the estimated\nsupport (predictive regions) looks relevant.\n\n## References\n.. [1] Gaonkar, B., & Davatzikos, C. (2012, October). Deriving statistical\n       significance maps for SVM based image classification and group\n       comparisons. In International Conference on Medical Image Computing\n       and Computer-Assisted Intervention (pp. 723-730). Springer, Berlin,\n       Heidelberg.\n\n.. [2] Chevalier, J. A., Nguyen, T. B., Salmon, J., Varoquaux, G.,\n       & Thirion, B. (2021). Decoding with confidence: Statistical\n       control on decoder maps. NeuroImage, 234, 117921.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports needed for this script\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nfrom nilearn import datasets\nfrom nilearn.image import mean_img\nfrom nilearn.input_data import NiftiMasker\nfrom nilearn.plotting import plot_stat_map, show\nfrom sklearn.cluster import FeatureAgglomeration\nfrom sklearn.feature_extraction import image\nfrom sklearn.linear_model import Ridge\nfrom sklearn.utils import Bunch\n\nfrom hidimstat.adaptive_permutation_threshold import ada_svr\nfrom hidimstat.clustered_inference import clustered_inference\nfrom hidimstat.ensemble_clustered_inference import ensemble_clustered_inference\nfrom hidimstat.permutation_test import permutation_test, permutation_test_cv\nfrom hidimstat.standardized_svr import standardized_svr\nfrom hidimstat.stat_tools import pval_from_scale, zscore_from_pval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to fetch and preprocess Haxby dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def preprocess_haxby(subject=2, memory=None):\n    \"\"\"Gathering and preprocessing Haxby dataset for a given subject.\"\"\"\n\n    # Gathering data\n    haxby_dataset = datasets.fetch_haxby(subjects=[subject])\n    fmri_filename = haxby_dataset.func[0]\n\n    behavioral = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n\n    # conditions = pd.DataFrame.to_numpy(behavioral['labels'])\n    conditions = behavioral[\"labels\"].values\n    session_label = behavioral[\"chunks\"].values\n\n    condition_mask = np.logical_or(conditions == \"face\", conditions == \"house\")\n    groups = session_label[condition_mask]\n\n    # Loading anatomical image (back-ground image)\n    if haxby_dataset.anat[0] is None:\n        bg_img = None\n    else:\n        bg_img = mean_img(haxby_dataset.anat)\n\n    # Building target where '1' corresponds to 'face' and '-1' to 'house'\n    y = np.asarray((conditions[condition_mask] == \"face\") * 2 - 1)\n\n    # Loading mask\n    mask_img = haxby_dataset.mask\n    masker = NiftiMasker(\n        mask_img=mask_img, standardize=True, smoothing_fwhm=None, memory=memory\n    )\n\n    # Computing masked data\n    fmri_masked = masker.fit_transform(fmri_filename)\n    X = np.asarray(fmri_masked)[condition_mask, :]\n\n    return Bunch(X=X, y=y, groups=groups, bg_img=bg_img, masker=masker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gathering and preprocessing Haxby dataset for a given subject\nThe `preprocess_haxby` function make the preprocessing of the Haxby dataset,\nit outputs the preprocessed activation maps for the two conditions\n'face' or 'house' (contained in `X`), the conditions (in `y`),\nthe session labels (in `groups`) and the mask (in `masker`).\nYou may choose a subject in [1, 2, 3, 4, 5, 6]. By default subject=2.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = preprocess_haxby(subject=2)\nX, y, groups, masker = data.X, data.y, data.groups, data.masker\nmask = masker.mask_img_.get_fdata().astype(bool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initializing FeatureAgglomeration object that performs the clustering\nFor fMRI data taking 500 clusters is generally a good default choice.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_clusters = 500\n# Deriving voxels connectivity.\nshape = mask.shape\nn_x, n_y, n_z = shape[0], shape[1], shape[2]\nconnectivity = image.grid_to_graph(n_x=n_x, n_y=n_y, n_z=n_z, mask=mask)\n# Initializing FeatureAgglomeration object.\nward = FeatureAgglomeration(n_clusters=n_clusters, connectivity=connectivity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Making the inference with several algorithms\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we try to recover the discriminative partern by computing\np-values from SVR decoder weights and a parametric approximation\nof the distribution of these weights.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We precomputed the regularization parameter by CV (C = 0.1) to reduce the\n# computation time of the example.\nbeta_hat, scale = standardized_svr(X, y, Cs=[0.1])\npval_std_svr, _, one_minus_pval_std_svr, _ = pval_from_scale(beta_hat, scale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we compute p-values thanks to permutation tests applied to\n1/the weights of the SVR decoder or 2/the weights of the Ridge decoder.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# To derive the p-values from the SVR decoder, you may change the next line by\n# `SVR_permutation_test_inference = True`. It should take around 15 minutes.\n\nSVR_permutation_test_inference = False\nif SVR_permutation_test_inference:\n    # We computed the regularization parameter by CV (C = 0.1)\n    pval_corr_svr_perm_test, one_minus_pval_corr_svr_perm_test = permutation_test_cv(\n        X, y, n_permutations=50, C=0.1\n    )\n\n# Another method is to compute the p-values by permutation test from the\n# Ridge decoder. The solution provided by this method should be very close to\n# the previous one and the computation time is much shorter: around 20 seconds.\n\nestimator = Ridge()\npval_corr_ridge_perm_test, one_minus_pval_corr_ridge_perm_test = permutation_test(\n    X, y, estimator=estimator, n_permutations=200\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let us run the algorithm introduced by Gaonkar et al. (c.f. References).\nSince the estimator they derive is obtained by approximating the hard margin\nSVM formulation, we referred to this method as \"ada-SVR\" which stands for\n\"Adaptive Permutation Threshold SVR\". The function is ``ada_svr``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "beta_hat, scale = ada_svr(X, y)\npval_ada_svr, _, one_minus_pval_ada_svr, _ = pval_from_scale(beta_hat, scale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the clustered inference algorithm which combines parcellation\nand high-dimensional inference (c.f. References).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "beta_hat, pval_cdl, _, one_minus_pval_cdl, _ = clustered_inference(\n    X, y, ward, n_clusters\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below, we run the ensemble clustered inference algorithm which adds a\nrandomization step over the clustered inference algorithm (c.f. References).\nTo make the example as short as possible we take `n_bootstraps=5`\nwhich means that 5 different parcellations are considered and\nthen 5 statistical maps are produced and aggregated into one.\nHowever you might benefit from clustering randomization taking\n`n_bootstraps=25` or `n_bootstraps=100`, also we set `n_jobs=2`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "beta_hat, pval_ecdl, _, one_minus_pval_ecdl, _ = ensemble_clustered_inference(\n    X, y, ward, n_clusters, groups=groups, n_bootstraps=5, n_jobs=2\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the results\nTo allow a better visualization of the disciminative pattern we will plot\nz-maps rather than p-value maps. Assuming Gaussian distribution of the\nestimators we can recover a z-score from a p-value by using the\ninverse survival function.\n\nFirst, we set theoretical FWER target at 10%.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples, n_features = X.shape\ntarget_fwer = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now translate the FWER target into a z-score target.\nFor the permutation test methods we do not need any additional correction\nsince the p-values are already adjusted for multiple testing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "zscore_threshold_corr = zscore_from_pval((target_fwer / 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Other methods need to be corrected. We consider the Bonferroni correction.\nFor methods that do not reduce the feature space, the correction\nconsists in dividing by the number of features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correction = 1.0 / n_features\nzscore_threshold_no_clust = zscore_from_pval((target_fwer / 2) * correction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For methods that parcelates the brain into groups of voxels, the correction\nconsists in dividing by the number of parcels (or clusters).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correction_clust = 1.0 / n_clusters\nzscore_threshold_clust = zscore_from_pval((target_fwer / 2) * correction_clust)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can plot the thresholded z-score maps by translating the\np-value maps estimated previously into z-score maps and using the\nsuitable threshold. For a better readability, we make a small function\ncalled `plot_map` that wraps all these steps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_map(\n    pval,\n    one_minus_pval,\n    zscore_threshold,\n    title=None,\n    cut_coords=[-25, -40, -5],\n    masker=masker,\n    bg_img=data.bg_img,\n):\n\n    zscore = zscore_from_pval(pval, one_minus_pval)\n    zscore_img = masker.inverse_transform(zscore)\n    plot_stat_map(\n        zscore_img,\n        threshold=zscore_threshold,\n        bg_img=bg_img,\n        dim=-1,\n        cut_coords=cut_coords,\n        title=title,\n    )\n\n\nplot_map(\n    pval_std_svr,\n    one_minus_pval_std_svr,\n    zscore_threshold_no_clust,\n    title=\"SVR parametric threshold\",\n)\n\nif SVR_permutation_test_inference:\n    plot_map(\n        pval_corr_svr_perm_test,\n        one_minus_pval_corr_svr_perm_test,\n        zscore_threshold_corr,\n        title=\"SVR permutation-test thresh.\",\n    )\n\nplot_map(\n    pval_corr_ridge_perm_test,\n    one_minus_pval_corr_ridge_perm_test,\n    zscore_threshold_corr,\n    title=\"Ridge permutation-test thresh.\",\n)\n\nplot_map(\n    pval_ada_svr,\n    one_minus_pval_ada_svr,\n    zscore_threshold_no_clust,\n    title=\"SVR adaptive perm. tresh.\",\n)\n\nplot_map(pval_cdl, one_minus_pval_cdl, zscore_threshold_clust, \"CluDL\")\n\nplot_map(pval_ecdl, one_minus_pval_ecdl, zscore_threshold_clust, \"EnCluDL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of the results\nAs advocated in introduction, the methods that do not reduce the original\nproblem are not satisfying since they are too conservative.\nAmong those methods, the only one that makes discoveries is the one that\nthreshold the SVR decoder using a parametric approximation.\nHowever this method has no statistical guarantees and we can see that some\nisolated voxels are discovered, which seems quite spurious.\nThe discriminative pattern derived from the clustered inference algorithm\n(CluDL) show that the method is less conservative.\nHowever, some reasonable paterns are also included in this solution.\nFinally, the solution provided by the ensemble clustered inference algorithm\n(EnCluDL) seems realistic as we recover the visual cortex and do not make\nspurious discoveries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}