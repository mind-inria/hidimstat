{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Measuring Individual and Group Variable Importance for Classification\n\nIn this example, we show on the Iris dataset how to measure variable importance for\nclassification tasks. We use two different variable importance methods: Conditional\nPermutation importance (CPI) and Permutation Feature Importance (PFI) with two different\nclassifiers: Logistic Regression (LR) and Support Vector Classifier (SVC). We start by\nmeasuring the importance of individual variables and then show how to measure the\nimportance of groups of variables.\n\nTo briefly summarize the two methods:\n\n - PFI (Permutation Feature Importance) shuffles the values of a feature and measures\n   the increase in the loss when predicting (using om the same full model) on the\n   shuffled data.\n\n - CPI (Conditional Permutation Importance) is a conditional version of PFI that\n   preserves the conditional distribution of the feature. It introduces a second model to\n   estimate this conditional distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom joblib import Parallel, delayed\nfrom scipy.stats import ttest_1samp\nfrom sklearn.base import clone\nfrom sklearn.datasets import load_iris\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.linear_model import LogisticRegressionCV, RidgeCV\nfrom sklearn.metrics import balanced_accuracy_score, hinge_loss, log_loss\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.svm import SVC\n\nfrom hidimstat import CPI, PermutationImportance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the iris dataset and add a spurious feature\nWe load the iris dataset and add a spurious feature that is a linear combination of\nthe petal length, width amd some noise but not related to the target. The spurious feature\nallows to illustrate that `PFI` is not robust to spurious features,\ncontrarily to `CPI`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = load_iris()\nrng = np.random.RandomState(0)\nX, y = dataset.data, dataset.target\nspurious_feat = X[:, 2] + X[:, 3]\nspurious_feat += rng.normal(size=X.shape[0], scale=np.std(spurious_feat) / 2)\nX = np.hstack([X, spurious_feat.reshape(-1, 1)])\n\ndataset.feature_names = dataset.feature_names + [\"spurious_feat\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measure variable importance\nSince both methods compute variable importance as a loss difference, they\nrequire a K-fold cross-fitting. Computing the importance for each fold is\nembarassingly parallel. For this reason, we encapsulate the main computations in a\nfunction and use joblib to parallelize the computation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def run_one_fold(X, y, model, train_index, test_index, vim_name=\"CPI\", groups=None):\n    model_c = clone(model)\n    model_c.fit(X[train_index], y[train_index])\n    y_pred = model_c.predict(X[test_index])\n\n    if isinstance(model_c, LogisticRegressionCV):\n        method = \"predict_proba\"\n        loss = log_loss\n        model_name = \"LogReg\"\n    else:\n        method = \"decision_function\"\n        loss = hinge_loss\n        model_name = \"SVC\"\n\n    if vim_name == \"CPI\":\n        vim = CPI(\n            estimator=model_c,\n            imputation_model_continuous=RidgeCV(alphas=np.logspace(-3, 3, 10)),\n            n_permutations=50,\n            random_state=0,\n            method=method,\n            loss=loss,\n        )\n    elif vim_name == \"PFI\":\n        vim = PermutationImportance(\n            estimator=model_c,\n            n_permutations=50,\n            random_state=0,\n            method=method,\n            loss=loss,\n        )\n\n    vim.fit(X[train_index], y[train_index], groups=groups)\n    importance = vim.importance(X[test_index], y[test_index])[\"importance\"]\n\n    return pd.DataFrame(\n        {\n            \"feature\": groups.keys(),\n            \"importance\": importance,\n            \"vim\": vim_name,\n            \"model\": model_name,\n            \"score\": balanced_accuracy_score(y_true=y[test_index], y_pred=y_pred),\n        }\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use two different classifiers: LR with cross-validation and SVC with a RBF kernel. We\nthen compute the importance for each (importance method, classifier, fold)\ncombination, in parallel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "models = [\n    LogisticRegressionCV(Cs=np.logspace(-3, 3, 10), tol=1e-3, max_iter=1000),\n    GridSearchCV(SVC(kernel=\"rbf\"), {\"C\": np.logspace(-3, 3, 10)}),\n]\ncv = KFold(n_splits=5, shuffle=True, random_state=0)\ngroups = {ft: i for i, ft in enumerate(dataset.feature_names)}\nout_list = Parallel(n_jobs=5)(\n    delayed(run_one_fold)(\n        X, y, model, train_index, test_index, vim_name=vim_name, groups=groups\n    )\n    for train_index, test_index in cv.split(X)\n    for model in models\n    for vim_name in [\"CPI\", \"PFI\"]\n)\ndf = pd.concat(out_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the importance values, we can compute the p-value of each feature. As we will\nsee, the p-values computed with `PFI` are not valid since the method\ndoes not provide type-1 error control.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_pval(df, threshold=0.05):\n    df_pval_list = []\n    for model in df[\"model\"].unique():\n        for vim in df[\"vim\"].unique():\n            for feature in df[\"feature\"].unique():\n                pval = ttest_1samp(\n                    df[\n                        (df[\"model\"] == model)\n                        & (df[\"vim\"] == vim)\n                        & (df[\"feature\"] == feature)\n                    ][\"importance\"],\n                    0,\n                    alternative=\"greater\",\n                ).pvalue\n                df_pval_list.append(\n                    {\n                        \"feature\": feature,\n                        \"vim\": vim,\n                        \"model\": model,\n                        \"pval\": pval,\n                        \"y_coord\": df[(df[\"vim\"] == vim)][\"importance\"].max(),\n                    }\n                )\n    df_pval = pd.DataFrame(df_pval_list)\n    df_pval = df_pval.query(f\"pval < {threshold}\")\n    return df_pval\n\n\nthreshold = 0.05\ndf_pval = compute_pval(df, threshold=threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization of the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_results(df_importance, df_pval):\n    fig, axes = plt.subplots(1, 2, figsize=(6, 3), sharey=True)\n    for method, ax in zip([\"CPI\", \"PFI\"], axes):\n        df_method = df_importance[df_importance[\"vim\"] == method]\n        legend = ax == axes[0]\n        sns.stripplot(\n            data=df_pval[df_pval[\"vim\"] == method],\n            x=\"y_coord\",\n            y=\"feature\",\n            hue=\"model\",\n            ax=ax,\n            edgecolor=\"k\",\n            linewidth=1,\n            marker=\"*\",\n            s=10,\n            legend=False,\n            dodge=0.5,\n            orient=\"h\",\n        )\n        sns.boxplot(\n            data=df_method,\n            x=\"importance\",\n            y=\"feature\",\n            hue=\"model\",\n            ax=ax,\n            legend=legend,\n            orient=\"h\",\n        )\n        ax.set_title(method, fontweight=\"bold\", y=1.12)\n        ax.axvline(0, color=\"k\", linestyle=\"--\")\n        ax.set_xlabel(\"Importance\")\n        ax.set_ylabel(\"\")\n        for i in range(len(df_method[\"feature\"].unique())):\n            if i % 2 == 0:\n                ax.axhspan(i - 0.5, i + 0.5, color=\"gray\", alpha=0.33)\n\n    ax = axes[0]\n    handles, labels = ax.get_legend_handles_labels()\n    ax.legend().remove()\n    handles.append(\n        plt.Line2D(\n            [0],\n            [0],\n            marker=\"*\",\n            color=\"w\",\n            markerfacecolor=\"w\",\n            markeredgecolor=\"k\",\n            markersize=12,\n            label=f\"pval < {threshold}\",\n            markeredgewidth=1.5,\n        )\n    )\n    fig.legend(\n        handles=handles,\n        labels=labels + [f\"pval < {threshold}\"],\n        loc=\"center\",\n        bbox_to_anchor=(0.6, 0.82),\n        ncol=3,\n    )\n    plt.tight_layout()\n    plt.show()\n\n\nplot_results(df, df_pval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The boxplot shows the importance of each feature, with colors indicating the\nclassifier used. A star marks the features that have a p-value (computed with a\nt-test) below 0.05. As expected, the spurious feature is not selected by CPI,\nbut is selected by Permutation Importance. It can also be seen that using the logistic\nregression model leads to greater statistical power than using the SVC model. This can\nbe explained by the small number of samples that do not allow leveraging the\nadditional flexibility of the SVC model. The SVC model could benefit from a more\nextensive hyperparameter search, especially optimizing the gamma parameter of the RBF\nkernel, which would be feasible with more data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measuring the importance of groups of features\nIn the example above, CPI did not select some features. This is because it\nmeasures conditional importance, which is the additional independent information a\nfeature provides knowing all the other features. When features are highly correlated,\nthis additional information decreases, resulting in lower importance rankings. To\nmitigate this issue, we can group correlated features together and measure the\nimportance of these feature groups. For instance, we can group 'sepal width' with\n'sepal length' and 'petal length' with 'petal width' and the spurious feature.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "groups = {\"sepal features\": [0, 1], \"petal features\": [2, 3, 4]}\nout_list = Parallel(n_jobs=5)(\n    delayed(run_one_fold)(\n        X, y, model, train_index, test_index, vim_name=vim_name, groups=groups\n    )\n    for train_index, test_index in cv.split(X)\n    for model in models\n    for vim_name in [\"CPI\", \"PFI\"]\n)\n\ndf_grouped = pd.concat(out_list)\ndf_pval = compute_pval(df_grouped, threshold=threshold)\nplot_results(df_grouped, df_pval)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}