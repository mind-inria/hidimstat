@inproceedings{Chamma_NeurIPS2023,
 author = {CHAMMA, Ahmad and Engemann, Denis A. and Thirion, Bertrand},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {67662--67685},
 publisher = {Curran Associates, Inc.},
 title = {Statistically Valid Variable Importance Assessment through Conditional Permutations},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/d60e14c19cd6e0fc38556ad29ac8fbc9-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@article{Chamma_AAAI2024,
title={Variable Importance in High-Dimensional Settings Requires Grouping},
volume={38}, url={https://ojs.aaai.org/index.php/AAAI/article/view/28997},
DOI={10.1609/aaai.v38i10.28997},
number={10},
journal={Proceedings of the AAAI Conference on Artificial Intelligence},
author={Chamma, Ahmad and Thirion, Bertrand and Engemann, Denis},
year={2024},
month={Mar.},
pages={11195-11203}
}

@InProceedings{pmlr-v119-nguyen20a,
  title = 	 {Aggregation of Multiple Knockoffs},
  author =       {Nguyen, Tuan-Binh and Chevalier, Jerome-Alexis and Thirion, Bertrand and Arlot, Sylvain},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {7283--7293},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/nguyen20a/nguyen20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/nguyen20a.html},
  abstract = 	 {We develop an extension of the knockoff inference procedure, introduced by Barber &amp; Candes (2015). This new method, called Aggregation of Multiple Knockoffs (AKO), addresses the instability inherent to the random nature of knockoff-based inference. Specifically, AKO improves both the stability and power compared with the original knockoff algorithm while still maintaining guarantees for false discovery rate control. We provide a new inference procedure, prove its core properties, and demonstrate its benefits in a set of experiments on synthetic and real datasets.}
}

@article{Meinshausen_2008,
author = {Nicolai Meinshausen, Lukas Meier and Peter Bühlmann},
title = {p-Values for High-Dimensional Regression},
journal = {Journal of the American Statistical Association},
volume = {104},
number = {488},
pages = {1671--1681},
year = {2009},
publisher = {Taylor \& Francis},
doi = {10.1198/jasa.2009.tm08647},
}

@article{bhy_2001,
author = {Benjamini, Yoav and Yekutieli, Daniel},
year = {2001},
month = {08},
pages = {},
title = {The Control of the False Discovery Rate in Multiple Testing Under Dependency},
volume = {29},
journal = {Ann. Stat.},
doi = {10.1214/aos/1013699998}
}

@article{Ren_2023,
    author = {Ren, Zhimei and Barber, Rina Foygel},
    title = "{Derandomised knockoffs: leveraging e-values for false discovery rate control}",
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {86},
    number = {1},
    pages = {122-154},
    year = {2023},
    month = {09},
    abstract = "{Model-X knockoffs is a flexible wrapper method for high-dimensional regression algorithms, which provides guaranteed control of the false discovery rate (FDR). Due to the randomness inherent to the method, different runs of model-X knockoffs on the same dataset often result in different sets of selected variables, which is undesirable in practice. In this article, we introduce a methodology for derandomising model-X knockoffs with provable FDR control. The key insight of our proposed method lies in the discovery that the knockoffs procedure is in essence an e-BH procedure. We make use of this connection and derandomise model-X knockoffs by aggregating the e-values resulting from multiple knockoff realisations. We prove that the derandomised procedure controls the FDR at the desired level, without any additional conditions (in contrast, previously proposed methods for derandomisation are not able to guarantee FDR control). The proposed method is evaluated with numerical experiments, where we find that the derandomised procedure achieves comparable power and dramatically decreased selection variability when compared with model-X knockoffs.}",
    issn = {1369-7412},
    doi = {10.1093/jrsssb/qkad085},
    url = {https://doi.org/10.1093/jrsssb/qkad085},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/86/1/122/56629998/qkad085.pdf},
}

@article{Candes_2018,
    author = {Candès, Emmanuel and Fan, Yingying and Janson, Lucas and Lv, Jinchi},
    title = "{Panning for Gold: ‘Model-X’ Knockoffs for High Dimensional Controlled Variable Selection}",
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {80},
    number = {3},
    pages = {551-577},
    year = {2018},
    month = {01},
    abstract = "{ Many contemporary large-scale applications involve building interpretable models linking a large set of potential covariates to a response in a non-linear fashion, such as when the response is binary. Although this modelling problem has been extensively studied, it remains unclear how to control the fraction of false discoveries effectively even in high dimensional logistic regression, not to mention general high dimensional non-linear models. To address such a practical problem, we propose a new framework of ‘model-X’ knockoffs, which reads from a different perspective the knockoff procedure that was originally designed for controlling the false discovery rate in linear models. Whereas the knockoffs procedure is constrained to homoscedastic linear models with n⩾p, the key innovation here is that model-X knockoffs provide valid inference from finite samples in settings in which the conditional distribution of the response is arbitrary and completely unknown. Furthermore, this holds no matter the number of covariates. Correct inference in such a broad setting is achieved by constructing knockoff variables probabilistically instead of geometrically. To do this, our approach requires that the covariates are random (independent and identically distributed rows) with a distribution that is known, although we provide preliminary experimental evidence that our procedure is robust to unknown or estimated distributions. To our knowledge, no other procedure solves the controlled variable selection problem in such generality but, in the restricted settings where competitors exist, we demonstrate the superior power of knockoffs through simulations. Finally, we apply our procedure to data from a case–control study of Crohn's disease in the UK, making twice as many discoveries as the original analysis of the same data.}",
    issn = {1369-7412},
    doi = {10.1111/rssb.12265},
    url = {https://doi.org/10.1111/rssb.12265},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/80/3/551/49274696/jrsssb\_80\_3\_551.pdf},
}

@article{breimanRandomForests2001,
  title = {Random {{Forests}}},
  author = {Breiman, Leo},
  year = {2001},
  month = oct,
  journal = {Machine Learning},
  volume = {45},
  number = {1},
  pages = {5--32},
  issn = {1573-0565},
  doi = {10.1023/A:1010933404324},
  urldate = {2022-06-28},
  abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148--156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
  langid = {english},
  keywords = {classification,ensemble,regression},
  file = {/home/ahmad/Zotero/storage/BYQ8Z75L/Breiman - 2001 - Random Forests.pdf}
}

@article{mi2021permutation,
  title={Permutation-based identification of important biomarkers for complex diseases via machine learning models},
  author={Mi, Xinlei and Zou, Baiming and Zou, Fei and Hu, Jianhua},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={3008},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{stroblConditionalVariableImportance2008,
  title = {Conditional Variable Importance for Random Forests},
  author = {Strobl, Carolin and Boulesteix, Anne-Laure and Kneib, Thomas and Augustin, Thomas and Zeileis, Achim},
  year = {2008},
  month = jul,
  journal = {BMC Bioinformatics},
  volume = {9},
  number = {1},
  pages = {307},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-9-307},
  urldate = {2022-01-12},
  abstract = {Random forests are becoming increasingly popular in many scientific fields because they can cope with "small n large p" problems, complex interactions and even highly correlated predictor variables. Their variable importance measures have recently been suggested as screening tools for, e.g., gene expression studies. However, these variable importance measures show a bias towards correlated predictor variables.},
  langid = {english},
  file = {/home/ahmad/Zotero/storage/ML7VF5ZJ/Strobl et al. - 2008 - Conditional variable importance for random forests.pdf}
}


@article{miPermutationbasedIdentificationImportant2021,
  title = {Permutation-Based Identification of Important Biomarkers for Complex Diseases via Machine Learning Models},
  author = {Mi, Xinlei and Zou, Baiming and Zou, Fei and Hu, Jianhua},
  year = {2021},
  month = may,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {3008},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-22756-2},
  urldate = {2022-01-12},
  abstract = {Study of human disease remains challenging due to convoluted disease etiologies and complex molecular mechanisms at genetic, genomic, and proteomic levels. Many machine learning-based methods have been developed and widely used to alleviate some analytic challenges in complex human disease studies. While enjoying the modeling flexibility and robustness, these model frameworks suffer from non-transparency and difficulty in interpreting each individual feature due to their sophisticated algorithms. However, identifying important biomarkers is a critical pursuit towards assisting researchers to establish novel hypotheses regarding prevention, diagnosis and treatment of complex human diseases. Herein, we propose a Permutation-based Feature Importance Test (PermFIT) for estimating and testing the feature importance, and for assisting interpretation of individual feature in complex frameworks, including deep neural networks, random forests, and support vector machines. PermFIT (available at https://github.com/SkadiEye/deepTL) is implemented in a computationally efficient manner, without model refitting. We conduct extensive numerical studies under various scenarios, and show that PermFIT not only yields valid statistical inference, but also improves the prediction accuracy of machine learning models. With the application to the Cancer Genome Atlas kidney tumor data and the HITChip atlas data, PermFIT demonstrates its practical usage in identifying important biomarkers and boosting model prediction performance.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Cancer,Data mining,Machine learning,Statistical methods},
}

@article{candesPanningGoldModelX2017,
  title = {Panning for {{Gold}}: {{Model-X Knockoffs}} for {{High-dimensional Controlled Variable Selection}}},
  shorttitle = {Panning for {{Gold}}},
  author = {Candes, Emmanuel and Fan, Yingying and Janson, Lucas and Lv, Jinchi},
  year = {2017},
  month = dec,
  journal = {arXiv:1610.02351 [math, stat]},
  eprint = {1610.02351},
  primaryclass = {math, stat},
  urldate = {2022-01-12},
  abstract = {Many contemporary large-scale applications involve building interpretable models linking a large set of potential covariates to a response in a nonlinear fashion, such as when the response is binary. Although this modeling problem has been extensively studied, it remains unclear how to effectively control the fraction of false discoveries even in high-dimensional logistic regression, not to mention general high-dimensional nonlinear models. To address such a practical problem, we propose a new framework of \$model\$-\$X\$ knockoffs, which reads from a different perspective the knockoff procedure (Barber and Cand{\textbackslash}`es, 2015) originally designed for controlling the false discovery rate in linear models. Whereas the knockoffs procedure is constrained to homoscedastic linear models with \$n{\textbackslash}ge p\$, the key innovation here is that model-X knockoffs provide valid inference from finite samples in settings in which the conditional distribution of the response is arbitrary and completely unknown. Furthermore, this holds no matter the number of covariates. Correct inference in such a broad setting is achieved by constructing knockoff variables probabilistically instead of geometrically. To do this, our approach requires the covariates be random (independent and identically distributed rows) with a distribution that is known, although we provide preliminary experimental evidence that our procedure is robust to unknown/estimated distributions. To our knowledge, no other procedure solves the \$controlled\$ variable selection problem in such generality, but in the restricted settings where competitors exist, we demonstrate the superior power of knockoffs through simulations. Finally, we apply our procedure to data from a case-control study of Crohn's disease in the United Kingdom, making twice as many discoveries as the original analysis of the same data.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Statistics Theory,Statistics - Applications,Statistics - Methodology},
  file = {/home/ahmad/Zotero/storage/YZ23F3Q5/Candes et al. - 2017 - Panning for Gold Model-X Knockoffs for High-dimen.pdf;/home/ahmad/Zotero/storage/ZSN64F6N/1610.html}
}

@article{liuFastPowerfulConditional2021,
  title = {Fast and {{Powerful Conditional Randomization Testing}} via {{Distillation}}},
  author = {Liu, Molei and Katsevich, Eugene and Janson, Lucas and Ramdas, Aaditya},
  year = {2021},
  month = jun,
  journal = {arXiv:2006.03980 [stat]},
  eprint = {2006.03980},
  primaryclass = {stat},
  urldate = {2022-01-12},
  abstract = {We consider the problem of conditional independence testing: given a response Y and covariates (X,Z), we test the null hypothesis that Y is independent of X given Z. The conditional randomization test (CRT) was recently proposed as a way to use distributional information about X{\textbar}Z to exactly (non-asymptotically) control Type-I error using any test statistic in any dimensionality without assuming anything about Y{\textbar}(X,Z). This flexibility in principle allows one to derive powerful test statistics from complex prediction algorithms while maintaining statistical validity. Yet the direct use of such advanced test statistics in the CRT is prohibitively computationally expensive, especially with multiple testing, due to the CRT's requirement to recompute the test statistic many times on resampled data. We propose the distilled CRT, a novel approach to using state-of-the-art machine learning algorithms in the CRT while drastically reducing the number of times those algorithms need to be run, thereby taking advantage of their power and the CRT's statistical guarantees without suffering the usual computational expense. In addition to distillation, we propose a number of other tricks like screening and recycling computations to further speed up the CRT without sacrificing its high power and exact validity. Indeed, we show in simulations that all our proposals combined lead to a test that has similar power to the most powerful existing CRT implementations but requires orders of magnitude less computation, making it a practical tool even for large data sets. We demonstrate these benefits on a breast cancer dataset by identifying biomarkers related to cancer stage.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Methodology},
}

@thesis{chevalier_statistical_2020,
	title = {Statistical control of sparse models in high dimension},
	url = {https://theses.hal.science/tel-03147200},
	institution = {Université Paris-Saclay},
	type = {phdthesis},
	author = {Chevalier, Jérôme-Alexis},
	urldate = {2024-10-17},
	date = {2020-12-11},
	langid = {english},
}
}

@article{benjamini1995controlling,
  title={Controlling the false discovery rate: a practical and powerful approach to multiple testing},
  author={Benjamini, Yoav and Hochberg, Yosef},
  journal={Journal of the Royal statistical society: series B (Methodological)},
  volume={57},
  number={1},
  pages={289--300},
  year={1995},
  publisher={Wiley Online Library}
}


@article{wang2022false,
  title={False discovery rate control with e-values},
  author={Wang, Ruodu and Ramdas, Aaditya},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={84},
  number={3},
  pages={822--852},
  year={2022},
  publisher={Oxford University Press}
}

@article{ramdas2017wasserstein,
  title={On wasserstein two-sample testing and related families of nonparametric tests},
  author={Ramdas, Aaditya and Garc{\'\i}a Trillos, Nicol{\'a}s and Cuturi, Marco},
  journal={Entropy},
  volume={19},
  number={2},
  pages={47},
  year={2017},
  publisher={MDPI}
}

@article{ramdas2017online,
  title={Online control of the false discovery rate with decaying memory},
  author={Ramdas, Aaditya and Yang, Fanny and Wainwright, Martin J and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{meinshausen2008hierarchical,
  title={Hierarchical testing of variable importance},
  author={Meinshausen, Nicolai},
  journal={Biometrika},
  volume={95},
  number={2},
  pages={265--278},
  year={2008},
  publisher={Oxford University Press}
}
@article{meinshausen2009p,
  title={P-values for high-dimensional regression},
  author={Meinshausen, Nicolai and Meier, Lukas and B{\"u}hlmann, Peter},
  journal={Journal of the American Statistical Association},
  volume={104},
  number={488},
  pages={1671--1681},
  year={2009},
  publisher={Taylor \& Francis}
}

@book{westfall1993resampling,
  title={Resampling-based multiple testing: Examples and methods for p-value adjustment},
  author={Westfall, Peter H and Young, S Stanley},
  volume={279},
  year={1993},
  publisher={John Wiley \& Sons}
}

@article{hirschhorn2005genome,
  title={Genome-wide association studies for common diseases and complex traits},
  author={Hirschhorn, Joel N and Daly, Mark J},
  journal={Nature reviews genetics},
  volume={6},
  number={2},
  pages={95--108},
  year={2005},
  publisher={Nature Publishing Group UK London}
}
@article{gaonkar_deriving_2012,
	title = {Deriving statistical significance maps for {SVM} based image classification and group comparisons},
	volume = {15},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3703958/},
	pages = {723--730},
	number = {0},
	journaltitle = {Medical image computing and computer-assisted intervention : {MICCAI} ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
	journal = {Med Image Comput Comput Assist Interv},
	author = {Gaonkar, Bilwaj and Davatzikos, Christos},
	urldate = {2024-12-16},
	year = {2012},
	pmid = {23285616},
	pmcid = {PMC3703958},
}
